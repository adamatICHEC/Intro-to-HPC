{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "\n",
    "### Context\n",
    "\n",
    "You have a model that predicts the sentiment of a film review (positive or negative) from the IMDB. There are two hyperparameters that format the data from IMDB: the maximum review length and the dictionary size. Below is a RNN model that predicts sentiment values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB\n",
    "\n",
    "The IMDB will be downloaded from the web if not installed locally. When installed will use the local version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "top_words = 100\n",
    "(Rev_train, Sc_train), (Rev_test, Sc_test) = imdb.load_data(num_words=top_words)\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(Rev_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(Rev_test, maxlen=max_review_length)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Here the model is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 16\n",
    "model_imdb = Sequential()\n",
    "model_imdb.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
    "model_imdb.add(Dropout(0.2))\n",
    "model_imdb.add(LSTM(10))\n",
    "model_imdb.add(Dropout(0.2))\n",
    "model_imdb.add(Dense(1, activation='sigmoid'))\n",
    "model_imdb.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_imdb.summary())\n",
    "plot_model(model_imdb,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "\n",
    "The cells below run the model and plot the results. **This could take some time without a GPU**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepoch = 150\n",
    "IMDB_history = model_imdb.fit(X_train,Sc_train,validation_data=(X_test,Sc_test),epochs=nepoch,batch_size=256)\n",
    "plt.plot(range(nepoch),IMDB_history['loss'],c='r')\n",
    "plt.plot(range(nepoch),IMDB_history['val_loss'],c='b')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(nepoch),IMDB_history['accuracy'],c='r')\n",
    "plt.plot(range(nepoch),IMDB_history['val_accuracy'],c='b')\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
